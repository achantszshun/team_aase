{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20676737-d418-44fa-bc25-ad0415f09c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import extract_data as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad947f5-26b9-491b-9819-026a51a844a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def npy_files_to_df(directory_path, batch_size=10, save_intermediate=True, output_path='output.csv'):\n",
    "#     dir_path = Path(directory_path)\n",
    "    \n",
    "#     # Get all .npy files in the directory\n",
    "#     npy_files = list(dir_path.glob('*.npy'))\n",
    "    \n",
    "#     if not npy_files:\n",
    "#         raise ValueError(f\"No .npy files found in {directory_path}\")\n",
    "    \n",
    "#     # Process files in batches\n",
    "#     for i in range(0, len(npy_files), batch_size):\n",
    "#         batch_files = npy_files[i:i + batch_size]\n",
    "#         batch_data = []\n",
    "        \n",
    "#         print(f\"Processing batch {i//batch_size + 1}/{(len(npy_files)-1)//batch_size + 1}\")\n",
    "        \n",
    "#         # Process each file in the current batch\n",
    "#         for file_path in batch_files:\n",
    "#             try:\n",
    "#                 # Load and process one file at a time\n",
    "#                 data = np.load(file_path)\n",
    "                \n",
    "#                 # Get shape information before flattening\n",
    "#                 shape_info = data.shape\n",
    "                \n",
    "#                 # Create row dict with filename and shape info\n",
    "#                 row_dict = {\n",
    "#                     'filename': file_path.name,\n",
    "#                     'original_shape': str(shape_info),\n",
    "#                     'total_points': data.size\n",
    "#                 }\n",
    "                \n",
    "#                 # Instead of storing all values, calculate some summary statistics\n",
    "#                 row_dict.update({\n",
    "#                     'mean': np.mean(data),\n",
    "#                     'std': np.std(data),\n",
    "#                     'min': np.min(data),\n",
    "#                     'max': np.max(data),\n",
    "#                     'median': np.median(data)\n",
    "#                 })\n",
    "                \n",
    "#                 # If you need actual mesh data points, you can add them selectively\n",
    "#                 # For example, store only the first 1000 points:\n",
    "#                 flattened = data.ravel()\n",
    "#                 for j, val in enumerate(flattened[:1000]):\n",
    "#                     row_dict[f'point_{j}'] = val\n",
    "                \n",
    "#                 batch_data.append(row_dict)\n",
    "                \n",
    "#                 # Clear memory\n",
    "#                 del data\n",
    "#                 del flattened\n",
    "#                 gc.collect()\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {file_path}: {str(e)}\")\n",
    "#                 continue\n",
    "        \n",
    "#         # Create DataFrame from batch\n",
    "#         df_batch = pd.DataFrame(batch_data)\n",
    "        \n",
    "#         # Save intermediate results if requested\n",
    "#         if save_intermediate:\n",
    "#             mode = 'w' if i == 0 else 'a'\n",
    "#             header = i == 0\n",
    "#             df_batch.to_csv(output_path, mode=mode, header=header, index=False)\n",
    "#             print(f\"Saved batch to {output_path}\")\n",
    "        \n",
    "#         # If not saving intermediate results, return the final DataFrame\n",
    "#         if not save_intermediate and i + batch_size >= len(npy_files):\n",
    "#             return df_batch\n",
    "        \n",
    "#         # Clear memory\n",
    "#         del df_batch\n",
    "#         gc.collect()\n",
    "    \n",
    "#     print(\"Processing complete!\")\n",
    "    \n",
    "#     if save_intermediate:\n",
    "#         print(f\"Final results saved to: {output_path}\")\n",
    "#         return pd.read_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e84a212-7f89-412f-8e4e-14800737cc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[287., 278., 414.],\n",
       "       [287., 278., 415.],\n",
       "       [287., 278., 416.],\n",
       "       ...,\n",
       "       [744., 391., 556.],\n",
       "       [744., 392., 556.],\n",
       "       [744., 393., 556.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_img = np.fromfile(\"/home/sid/DeepView/volumes/scan_001.raw\", dtype = np.dtype('<u2'))\n",
    "raw_img = np.reshape(np.array(raw_img), (1280, 768, 768)).astype(np.float32)\n",
    "\n",
    "points = dt.extract_point_data(raw_img)\n",
    "vertices = dt.extract_vertices(points)\n",
    "vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abf3c12-3bfd-45ba-98e7-9af396086f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to process: 87\n",
      "Processing batch 1/9...\n",
      "Batch 1 completed and saved.\n",
      "Processing batch 2/9...\n",
      "Batch 2 completed and saved.\n",
      "Processing batch 3/9...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Load and reshape raw image\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     raw_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromfile(file_path, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<u2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 25\u001b[0m     raw_img \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_img\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1280\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Process the image\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     points \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mextract_point_data(raw_img)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the directory containing raw files\n",
    "raw_files_directory = \"/home/sid/DeepView/volumes\"\n",
    "\n",
    "# Initialize an empty list to store data for DataFrame\n",
    "compiled_data = []\n",
    "\n",
    "# List all .raw files in the directory\n",
    "raw_files = [file for file in os.listdir(raw_files_directory) if file.endswith(\".raw\")]\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 10\n",
    "total_files = len(raw_files)\n",
    "print(f\"Total files to process: {total_files}\")\n",
    "\n",
    "# Process files in batches\n",
    "for i in range(0, total_files, batch_size):\n",
    "    batch = raw_files[i:i + batch_size]\n",
    "    print(f\"Processing batch {i // batch_size + 1}/{(total_files - 1) // batch_size + 1}...\")\n",
    "\n",
    "    for file_name in batch:\n",
    "        file_path = os.path.join(raw_files_directory, file_name)\n",
    "        try:\n",
    "            # Load and reshape raw image\n",
    "            raw_img = np.fromfile(file_path, dtype=np.dtype('<u2'))\n",
    "            raw_img = np.reshape(np.array(raw_img), (1280, 768, 768)).astype(np.float32)\n",
    "            \n",
    "            # Process the image\n",
    "            points = dt.extract_point_data(raw_img)\n",
    "            vertices = dt.extract_vertices(points)\n",
    "            \n",
    "            # Compile the data into a dictionary\n",
    "            compiled_data.append({\n",
    "                \"file_name\": file_name,\n",
    "                \"vertices\": vertices\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "    \n",
    "    # Save intermediate results to avoid data loss\n",
    "    temp_df = pd.DataFrame(compiled_data)\n",
    "    temp_df.to_csv(\"compiled_mesh_data_temp.csv\", index=False)\n",
    "    print(f\"Batch {i // batch_size + 1} completed and saved.\")\n",
    "\n",
    "# Convert compiled data into a final DataFrame\n",
    "mesh_data_df = pd.DataFrame(compiled_data)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "mesh_data_df.to_csv(\"compiled_mesh_data.csv\", index=False)\n",
    "\n",
    "print(\"All files processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32dcfba8-dd9f-4e37-88b6-11d95ad4276f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_name                                         scan_046.raw\n",
       "vertices     [[335. 411. 404.]\\n [335. 411. 405.]\\n [335. 4...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_arrays = pd.read_csv(\"compiled_mesh_data.csv\")\n",
    "mesh_arrays.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607c47e-f53d-4a72-933d-02f05d2d866d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
