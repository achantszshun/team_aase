{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d372acbc-d48b-4acc-b464-59cd7570ebd7",
   "metadata": {},
   "source": [
    " # Team AASE takes on DeepView\n",
    " The aim of this project is to produce a deep learning model that can take 2D slices of a 3D mesh object, and produce an accurate imitation of the object, sort of like a 3D printer! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3c228-15bd-42af-b286-00730f98a0a4",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabeba74-b1cf-45f6-9ae6-c58db4dc8d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1665032-8ae1-4fac-a725-e15185399d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from skimage import measure\n",
    "from scipy.ndimage import zoom\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc358b-3252-40ed-ac6f-547d723935e4",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "The 2D slices given to us are stored in `.raw` files, our first objective is to store them as 3D arrays and combined all of them into a singular dataframe that can be utilized for analysis. We first convert the `.raw` files into `.npy` files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d63ef2a9-9eed-4dcd-97d5-0bc2ffc4cef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mesh_data = pd.read_csv('compiled_mesh_data.csv')\n",
    "mesh_data.head(6) \n",
    "\n",
    "#filter out empty rows\n",
    "# List of problematic scans\n",
    "invalid_scans = ['scan_053.raw', 'scan_043.raw', 'scan_089.raw']\n",
    "\n",
    "# Filter out the rows with these scans\n",
    "mesh_data = mesh_data[~mesh_data['file_name'].isin(invalid_scans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "125d2d73-be5b-4a7d-8a2d-eda866c07201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [[335.0, 411.0, 404.0], [335.0, 411.0, 405.0],...\n",
      "1    [[301.0, 376.0, 383.0], [301.0, 379.0, 386.0],...\n",
      "2    [[461.0, 349.0, 299.0], [461.0, 349.0, 300.0],...\n",
      "3    [[385.0, 342.0, 392.0], [385.0, 342.0, 393.0],...\n",
      "4    [[481.0, 374.0, 424.0], [481.0, 374.0, 425.0],...\n",
      "Name: vertices, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def convert_to_float_array(entry):\n",
    "    # Convert bytes to string if needed\n",
    "    if isinstance(entry, bytes):\n",
    "        entry = entry.decode(\"utf-8\")  # Decode bytes to string\n",
    "    \n",
    "    # Use regex to find all floating point or integer numbers in the string\n",
    "    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", entry)\n",
    "    \n",
    "    # Convert found numbers to floats and return as a numpy array\n",
    "    return np.array([float(num) for num in numbers], dtype=np.float32).reshape(-1, 3)  # Reshape if coordinates are (N, 3)\n",
    "\n",
    "# Ensure all entries in the 'vertices' column are strings\n",
    "mesh_data['vertices'] = mesh_data['vertices'].apply(lambda x: x.decode(\"utf-8\") if isinstance(x, bytes) else x)\n",
    "\n",
    "# Apply the function to the 'vertices' column\n",
    "mesh_clean = mesh_data['vertices'].apply(convert_to_float_array)\n",
    "\n",
    "# Verify the output\n",
    "print(mesh_clean.head())  # Check the first few parsed rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be50de-cad0-4246-ad46-82a66d911e0a",
   "metadata": {},
   "source": [
    "### Creating and Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "946116f2-2bb0-49dd-8a06-5c0fb60bb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_voxel_grid(vertices, grid_size=256):\n",
    "    \"\"\"\n",
    "    Map vertices to a normalized voxel grid.\n",
    "\n",
    "    Parameters:\n",
    "    - vertices: numpy array of shape (N, 3).\n",
    "    - grid_size: Size of the voxel grid along each axis.\n",
    "\n",
    "    Returns:\n",
    "    - A voxel grid of shape (grid_size, grid_size, grid_size).\n",
    "    \"\"\"\n",
    "    voxel_grid = np.zeros((grid_size, grid_size, grid_size), dtype=np.float32)\n",
    "\n",
    "    if vertices.shape[0] == 0:\n",
    "        print(\"Empty vertex array.\")\n",
    "        return voxel_grid\n",
    "\n",
    "    # Normalize vertices to the grid size\n",
    "    min_vals = vertices.min(axis=0)\n",
    "    max_vals = vertices.max(axis=0)\n",
    "\n",
    "    if np.any(max_vals - min_vals == 0):  # Check for flat ranges\n",
    "        print(\"Flat vertex range. Check input data.\")\n",
    "        return voxel_grid\n",
    "\n",
    "    vertices_normalized = ((vertices - min_vals) / (max_vals - min_vals)) * (grid_size - 1)\n",
    "    indices = vertices_normalized.astype(int)\n",
    "\n",
    "    # Populate the grid\n",
    "    for x, y, z in indices:\n",
    "        x, y, z = np.clip([x, y, z], 0, grid_size - 1)\n",
    "        voxel_grid[x, y, z] = 1.0\n",
    "\n",
    "    return voxel_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bad58576-ebcf-460a-8717-c387555c3abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m voxel_grid \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_voxel_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m visualize_voxel_grid_with_slider(voxel_grid)\n",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m, in \u001b[0;36mcreate_voxel_grid\u001b[0;34m(vertices, grid_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m voxel_grid\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Normalize vertices to the grid size\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m min_vals \u001b[38;5;241m=\u001b[39m \u001b[43mvertices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m max_vals \u001b[38;5;241m=\u001b[39m vertices\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(max_vals \u001b[38;5;241m-\u001b[39m min_vals \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):  \u001b[38;5;66;03m# Check for flat ranges\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/pandas/core/series.py:6507\u001b[0m, in \u001b[0;36mSeries.min\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6499\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(\n\u001b[1;32m   6501\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6505\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6506\u001b[0m ):\n\u001b[0;32m-> 6507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/pandas/core/generic.py:12388\u001b[0m, in \u001b[0;36mNDFrame.min\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(\n\u001b[1;32m  12382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12383\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12386\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12387\u001b[0m ):\n\u001b[0;32m> 12388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  12390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  12391\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  12392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  12393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  12394\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  12395\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/pandas/core/series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6452\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[1;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6456\u001b[0m     )\n\u001b[0;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/pandas/core/nanops.py:1098\u001b[0m, in \u001b[0;36m_nanminmax.<locals>.reduction\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _na_for_min_count(values, axis)\n\u001b[1;32m   1095\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m _get_values(\n\u001b[1;32m   1096\u001b[0m     values, skipna, fill_value_typ\u001b[38;5;241m=\u001b[39mfill_value_typ, mask\u001b[38;5;241m=\u001b[39mmask\n\u001b[1;32m   1097\u001b[0m )\n\u001b[0;32m-> 1098\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_null_out(result, axis, mask, values\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/numpy/_core/_methods.py:49\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "\n",
    "def visualize_voxel_grid_with_slider(voxel_grid):\n",
    "    \"\"\"\n",
    "    Visualize slices of a voxel grid with an interactive slider.\n",
    "    \n",
    "    Parameters:\n",
    "    - voxel_grid: A 3D numpy array representing the voxel grid.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    \n",
    "    # Initial slice index\n",
    "    slice_idx = voxel_grid.shape[2] // 2\n",
    "    im = ax.imshow(voxel_grid[:, :, slice_idx], cmap='gray')\n",
    "    ax.set_title(f\"Slice {slice_idx}\")\n",
    "    \n",
    "    # Create the slider\n",
    "    ax_slider = plt.axes([0.25, 0.1, 0.65, 0.03])  # [left, bottom, width, height]\n",
    "    slider = Slider(ax_slider, 'Slice', 0, voxel_grid.shape[2] - 1, valinit=slice_idx, valstep=1)\n",
    "    \n",
    "    # Update function for slider\n",
    "    def update(val):\n",
    "        slice_idx = int(slider.val)\n",
    "        im.set_data(voxel_grid[:, :, slice_idx])\n",
    "        ax.set_title(f\"Slice {slice_idx}\")\n",
    "        fig.canvas.draw_idle()\n",
    "    \n",
    "    slider.on_changed(update)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "voxel_grid = create_voxel_grid(mesh_clean)\n",
    "visualize_voxel_grid_with_slider(voxel_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a0cfe-79b6-4403-b25b-e9a5b1ad5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighResolutionAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HighResolutionAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7f470-6596-441c-810f-4b231fa43d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_voxel_grid(vertices, grid_size=64):\n",
    "    \"\"\"\n",
    "    Create a voxel grid from vertices.\n",
    "\n",
    "    Parameters:\n",
    "    - vertices: numpy array of shape (N, 3), where N is the number of vertices.\n",
    "    - grid_size: Size of the voxel grid along each axis.\n",
    "\n",
    "    Returns:\n",
    "    - A 3D numpy array representing the voxel grid.\n",
    "    \"\"\"\n",
    "    voxel_grid = np.zeros((grid_size, grid_size, grid_size), dtype=np.float32)\n",
    "    \n",
    "    # Normalize vertices to fit within the grid\n",
    "    min_vals = vertices.min(axis=0)\n",
    "    max_vals = vertices.max(axis=0)\n",
    "    normalized_vertices = (vertices - min_vals) / (max_vals - min_vals) * (grid_size - 1)\n",
    "    indices = normalized_vertices.astype(int)\n",
    "\n",
    "    for x, y, z in indices:\n",
    "        x, y, z = np.clip([x, y, z], 0, grid_size - 1)\n",
    "        voxel_grid[x, y, z] = 1\n",
    "    return voxel_grid\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for vertices in mesh_clean:  # Loop through each set of vertices in the dataset\n",
    "        # Create a voxel grid\n",
    "        input_grid = create_voxel_grid(vertices)  # Shape: (64, 64, 64)\n",
    "\n",
    "        # Convert to PyTorch tensor\n",
    "        input_tensor = torch.tensor(input_grid, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)  # Shape: (1, 1, 64, 64, 64)\n",
    "\n",
    "        # Add noise\n",
    "        noisy_input = input_tensor + torch.randn_like(input_tensor) * 0.01\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(noisy_input)\n",
    "        loss = criterion(outputs, input_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Monitor training progress\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(mesh_clean):.4f}\")\n",
    "\n",
    "    # Visualize outputs every few epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            sample_output = outputs[0, 0].cpu().numpy()\n",
    "            plt.imshow(sample_output[32], cmap='gray')  # Visualize a slice\n",
    "            plt.title(f\"Epoch {epoch+1} - Reconstruction\")\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfc930-9856-4cc9-9dc0-697e2d364234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sample from the dataset\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    sample_idx = 49  # Change this to visualize different scans\n",
    "    input_voxel = train_tensor[sample_idx].unsqueeze(0).to(device)  # Add batch dimension\n",
    "    reconstructed_voxel = model(input_voxel).squeeze().cpu().numpy()  # Remove batch and channel dims\n",
    "\n",
    "# Visualize the reconstructed voxel grid along different slices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(reconstructed_voxel[:, :, 32], cmap='gray')  # Slice along Z-axis\n",
    "plt.title('Z-axis Slice')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(reconstructed_voxel[:, 32, :], cmap='gray')  # Slice along Y-axis\n",
    "plt.title('Y-axis Slice')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(reconstructed_voxel[32, :, :], cmap='gray')  # Slice along X-axis\n",
    "plt.title('X-axis Slice')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95681552-0a26-4ee3-9f21-ba76faf793cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_mesh_from_data(data, threshold=None):\n",
    "    # Check data range and dynamically set threshold if none is provided\n",
    "    data_min, data_max = np.min(data), np.max(data)\n",
    "    if threshold is None:\n",
    "        threshold = data_min + (data_max - data_min) * 0.05  # Start with 5% of max range\n",
    "\n",
    "    print(f\"Using threshold: {threshold}\")\n",
    "    print(f\"Data range: min={data_min}, max={data_max}\")\n",
    "\n",
    "    # Extract vertices and faces using marching cubes\n",
    "    try:\n",
    "        verts, faces, _, _ = measure.marching_cubes(data, level=threshold)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in marching cubes: {e}\")\n",
    "        return\n",
    "\n",
    "    # Extract the x, y, z coordinates of the vertices\n",
    "    x, y, z = verts[:, 0], verts[:, 1], verts[:, 2]\n",
    "    \n",
    "    # Plot the 3D mesh with enhanced visibility\n",
    "    fig = go.Figure(data=[go.Mesh3d(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z,\n",
    "        i=faces[:, 0],\n",
    "        j=faces[:, 1],\n",
    "        k=faces[:, 2],\n",
    "        color='lightblue',\n",
    "        opacity=0.7,\n",
    "        lighting=dict(ambient=0.5, diffuse=0.5, roughness=0.1, specular=0.5)\n",
    "    )])\n",
    "    \n",
    "    # Adjust axis ranges dynamically using `aspectmode='data'`\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=\"X\"),\n",
    "            yaxis=dict(title=\"Y\"),\n",
    "            zaxis=dict(title=\"Z\"),\n",
    "            aspectmode='data'  # Adjust aspect ratio based on data range\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        margin=dict(l=50, r=50, b=100, pad=4),\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe921a-b791-4c8a-8196-a64fa4c91396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import measure\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_mesh_from_data(data, threshold=None):\n",
    "    \"\"\"\n",
    "    Plot a 3D mesh from voxel grid data.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: 3D numpy array representing the voxel grid.\n",
    "    - threshold: Threshold value for the marching cubes algorithm.\n",
    "    \"\"\"\n",
    "    # Check data range and dynamically set threshold if none is provided\n",
    "    data_min, data_max = np.min(data), np.max(data)\n",
    "    if threshold is None:\n",
    "        threshold = data_min + (data_max - data_min) * 0.05  # Default: 5% of range\n",
    "\n",
    "    print(f\"Using threshold: {threshold}\")\n",
    "    print(f\"Data range: min={data_min}, max={data_max}\")\n",
    "\n",
    "    # Extract vertices and faces using marching cubes\n",
    "    try:\n",
    "        verts, faces, _, _ = measure.marching_cubes(data, level=threshold)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in marching cubes: {e}\")\n",
    "        return\n",
    "\n",
    "    # Extract the x, y, z coordinates of the vertices\n",
    "    x, y, z = verts[:, 0], verts[:, 1], verts[:, 2]\n",
    "    \n",
    "    # Plot the 3D mesh with enhanced visibility\n",
    "    fig = go.Figure(data=[go.Mesh3d(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z,\n",
    "        i=faces[:, 0],\n",
    "        j=faces[:, 1],\n",
    "        k=faces[:, 2],\n",
    "        color='lightblue',\n",
    "        opacity=0.7,\n",
    "        lighting=dict(ambient=0.5, diffuse=0.5, roughness=0.1, specular=0.5)\n",
    "    )])\n",
    "    \n",
    "    # Adjust layout for better visualization\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=\"X\", range=[-5, 70]),  # Adjust range based on data\n",
    "            yaxis=dict(title=\"Y\", range=[-5, 70]),\n",
    "            zaxis=dict(title=\"Z\", range=[-5, 70]),\n",
    "            aspectmode='cube'  # Keep aspect ratio equal\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        margin=dict(l=50, r=50, b=100, pad=4),\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad4ad5-0d8f-4418-a071-21a720797c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reconstructed_voxel is a 3D numpy array from the model's output\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    sample_idx = 0  # Change this to visualize a different scan\n",
    "    input_voxel = train_tensor[sample_idx].unsqueeze(0).to(device)  # Add batch dimension\n",
    "    reconstructed_voxel = model(input_voxel).squeeze().cpu().numpy()  # Remove batch and channel dims\n",
    "\n",
    "# Plot the reconstructed voxel grid in 3D\n",
    "plot_mesh_from_data(reconstructed_voxel, threshold=0.001)  # Adjust threshold if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524e0b4-da34-4af6-8ce5-c4475971e3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b645ff-84e7-4a59-9aa1-a38cf885103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_2d_slices(original_scan, reconstructed_data, slice_index=5):\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "    # Original scan X-axis slice (scaled)\n",
    "    axes[0, 0].imshow(np.squeeze(original_scan[slice_index, :, :]) / 65535, cmap='gray')\n",
    "    axes[0, 0].set_title(\"Original X-axis Slice\")\n",
    "    axes[0, 1].imshow(reconstructed_data[slice_index, :, :], cmap='gray')\n",
    "    axes[0, 1].set_title(\"Reconstructed X-axis Slice\")\n",
    "    \n",
    "    # Original scan Y-axis slice (scaled)\n",
    "    axes[1, 0].imshow(np.squeeze(original_scan[:, slice_index, :]) / 65535, cmap='gray')\n",
    "    axes[1, 0].set_title(\"Original Y-axis Slice\")\n",
    "    axes[1, 1].imshow(reconstructed_data[:, slice_index, :], cmap='gray')\n",
    "    axes[1, 1].set_title(\"Reconstructed Y-axis Slice\")\n",
    "    \n",
    "    # Original scan Z-axis slice (scaled)\n",
    "    axes[2, 0].imshow(np.squeeze(original_scan[:, :, slice_index]) / 65535, cmap='gray')\n",
    "    axes[2, 0].set_title(\"Original Z-axis Slice\")\n",
    "    axes[2, 1].imshow(reconstructed_data[:, :, slice_index], cmap='gray')\n",
    "    axes[2, 1].set_title(\"Reconstructed Z-axis Slice\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#To sid: set the first raw scan here as scan_001 and run the function below\n",
    "plot_2d_slices(raw_img, reconstructed_tensor, slice_index=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904ec5e-29c3-4975-94c8-54b342a0ab74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb6898-69b2-4b4c-b3b4-cf7639a05978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
